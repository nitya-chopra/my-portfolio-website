---
categories:
- ""
- ""
date: "2017-10-31T21:28:43-05:00"
description: ""
draft: false
image: climate.jpg
keywords: ""
slug: project3
title: It's Getting Hot In Here
---

```{r load-libraries, include=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
#install.packages(infer)
```

# Climate change and temperature anomalies 

To study climate change, we found data on the *Combined Land-Surface Air and Sea-Surface Water Temperature Anomalies* in the Northern Hemisphere at NASA's Goddard Institute for Space Studies. 

We ran the code below to load the file:

```{r weather_data, cache=TRUE}
weather <- read_csv("https://data.giss.nasa.gov/gistemp/tabledata_v3/NH.Ts+dSST.csv", 
           skip = 1, #skip one row as real data starts from row 2
           na = "***") #missing data is coded as *** so we specify that here
weather
```

Next, we cleaned the dataset - discarded unwanted columns and converted the wide format to a long format.

```{r tidyweather}
# dropping columns we don't need
weather2 <- weather %>% select(-`J-D`, -`D-N`, -DJF, -MAM, -JJA, -SON)
weather2

# converting dataframe from wide to long format using pivot_longer( ) 
tidyweather <- weather2 %>% pivot_longer(cols=2:13, names_to="month", values_to="delta")
tidyweather
```

On further inspection, our dataframe has three variables now - one each for year, month and delta (temperature deviation). 

## Plotting Information

We plotted the data using a time-series scatter plot, and added a trendline. We used 'lubridate' for dates to ensure that delta plots chronologically.

```{r scatter_plot}

options(warn=-1)

# reformatting dates
tidyweather <- tidyweather %>%
  mutate(date = ymd(paste(as.character(Year), month, "1")), # lubridate used here
         month = month(date, label=TRUE),
         Year = year(date)) 

# plotting temperature deviation 
ggplot(tidyweather, aes(x=date, y = delta))+
  geom_point(alpha=0.5) +
  geom_smooth(color="red") +
  theme_bw() +
  theme(
    plot.title=element_text(face="bold")
  ) +
  labs (
    title = "Weather Anomalies",
    subtitle = "Trends in temperature deviations over the period 1880 - 2019",
    x = "Year",
    y = "Temperature Deviation"
  )
```

Next, we studied the effect of increasing temperature by month. 
 
```{r facet_wrap}

options(warn=-1)

# plotting scatterplot and trend lines by month
ggplot(tidyweather, aes(x=date, y = delta))+
  geom_point(size=0.5, alpha=0.6)+
  geom_smooth(color="red") +
  facet_wrap(~month) + # to separate plots by month
  theme_bw() +
  theme(
    plot.title=element_text(face="bold")
  ) +
  labs (
    title = "It's Getting Hot in Here",
    subtitle="Trends in temperature deviations BY MONTH between 1880 and 2019",
    y="Temperature Deviation",
    x="Year"
  )
```

> Overall, we see a gradual rise in the average temperature across all twelve months from 1880 to 2019 owing to Global Warming. This rise has been greater for winter months such as January, February, November and December, compared to summer months such as May, June, July and August. 

> Another point worth mentioning is that the winter months depict greater deviation (the points are more scattered around the trendline) compared to summer months which have relatively lower deviation (the points are closer to the trendline)

Since it is sometimes useful to group data into different time periods to study historical data, we created a new data frame called `comparison` that groups data into five time periods: 1881-1920, 1921-1950, 1951-1980, 1981-2010 and 2011-present. 

```{r intervals}

comparison <- tidyweather %>% 
  filter(Year>= 1881) %>%     #remove years prior to 1881
  #create new variable 'interval', and assign values based on criteria below:
  mutate(interval = case_when(
    Year %in% c(1881:1920) ~ "1881-1920",
    Year %in% c(1921:1950) ~ "1921-1950",
    Year %in% c(1951:1980) ~ "1951-1980",
    Year %in% c(1981:2010) ~ "1981-2010",
    TRUE ~ "2011-present"
  ))

comparison
```

Once we had intervals, we studied the distribution of monthly deviations (`delta`), grouped by the different time periods we were interested in. 

```{r density_plot}

ggplot(comparison, aes(x=delta, fill=interval)) + #fill to group and colour by different time intervals
  geom_density(alpha=0.2) +   #density plot with transparency set to 20%
  theme_bw( ) +               # theme white background and grey lines
  theme(
    plot.title=element_text(face="bold") # make title bold
  ) +
  labs (
    title="Distribution of Monthly Deviations",
    subtitle = "Density plot grouped by different time intervals ",
    y = "",
    x = "Temperature Deviation",
    legend.title=""
    ) +
  guides(fill=guide_legend((title="Time Interval"))) #change legend title

```
Later, we studied average annual anomalies as well. 

```{r averaging}

options(warn=-1)

#creating yearly averages
average_annual_anomaly <- tidyweather %>% 
  group_by(Year) %>%   #grouping data by Year
  
  # creating summaries for mean delta 
  summarise(annual_average_delta = mean(delta, na.rm=TRUE)) # use `na.rm=TRUE` to eliminate NA (not available) values

#plotting the data:
ggplot(average_annual_anomaly, aes(x=Year, y= annual_average_delta))+
  geom_point()+
  geom_smooth(method="loess", color="red") +  # fit the best fit line, using LOESS method
  theme_bw() +
  theme(
    plot.title = element_text(face="bold")
  ) +
  labs (
    title = "Average Yearly Anomaly",
    y     = "Average Annual Temperature Deviations"
  )                         
```
## Confidence Interval for `delta`

> A one-degree global change is significant because it takes a vast amount of heat to warm all the oceans, atmosphere, and land by that much. In the past, a one- to two-degree drop was all it took to plunge the Earth into the Little Ice Age.

We constructed a confidence interval for the average annual 'delta' since 2011, using two different methods 

**(1) a formula** 

```{r, calculate_CI_using_formula}

formula_CI <- comparison %>% 
                filter(interval=="2011-present") %>% # filter for time period we're interested in
                summarise(mean=mean(delta, na.rm=TRUE), # calculate summary statistics for delta
                          SD=sd(delta, na.rm=TRUE), 
                          count=n(), 
                          SE=SD/sqrt(count),
                          lower_CI = mean - 1.96*SE,
                          upper_CI = mean + 1.96*SE
                          )

formula_CI
```

**(2) bootstrap simulation with the `infer` package**

```{r, calculate_CI_using_bootstrap}

# use the infer package to construct a 95% CI for delta
library(infer)

set.seed(1234)
whatever_id_like <- comparison %>% 
  filter(interval=="2011-present") %>%      # filtering for time period we're interested in
  specify(response=delta) %>%               # specifying what we're calculating CI for
  generate(reps=1000, type="bootstrap") %>% # generate random samples or reps using bootstrap
  calculate(stat="mean")                    # calculate mean
  
percentile_CI <- whatever_id_like %>% 
                 get_confidence_interval(comparison$delta, level=0.95, type="percentile")
percentile_CI
```

> The first method calculates summary statistics and confidence intervals (CI) using the whole data for temperature deviations (delta) from 2011 to present. On the other hand, the bootstrap method creates 1000 random samples (reps), and calculates their means on the basis of which we arrive at CIs. 

> The 95% lower CI and upper CI is 0.917 and 1.02 respectively, which means that out of every 1000 samples, we are confident that for 950 samples the range [0.917, 1.02] would correctly contain the true mean of the population.      